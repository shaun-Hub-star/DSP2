package org.example;

import com.sun.corba.se.spi.ior.Writeable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.omg.CORBA_2_3.portable.OutputStream;

import java.util.Arrays;
import java.util.HashSet;

public class PartedText{
    private final int part;
    private final String[] words;
    private final Text text;

    public PartedText(LongWritable key, Text line){
        //line: <w1> <w2> <w3>\t<...>
        this.part = Math.random() > 0.5 ? 1 : 0;
        /*
        * TODO: change this when running on hadoops
        * */
        //this.part = (int) key.get() % 2;
        String lowerWords = line.toString().toLowerCase().split("\\t")[0];
        this.words = lowerWords.split("\\s");
        this.text = new Text(part + "\t" + lowerWords);
    }

    //for the reducer
    public PartedText(Text text){
        this.text = text;
        String[] split = text.toString().split("\\s");
        this.part = Integer.parseInt(split[0]);
        this.words = Arrays.copyOfRange(split, 1, split.length);
    }

    public boolean hasIllegalCharacter() {
        // generated by your mamai
        for (String word : words) {
            if (!word.matches("\\w+")) {
                System.out.println("log(not clickbait!!??!?): mama_AI_MACHINE_LEANING_NODER_CHATGPT_BAKABA Found illegal char in the word: " + word);
                return true;//אמת
            }
        }
        return false;//שקר
    }

    public boolean hasStopWord(HashSet<String> stopWords) {
        for (String word : words) {
            if (stopWords.contains(word)) {
                System.out.println("Found a stop word: " + word);
                return true;//אמת
            }
        }
        return false;//שקר
    }

    public int getPart() {
        return part;
    }

    public int getNumOfWords(){
        return words.length;
    }

    public Text getText(){
        return this.text;
    }


}
